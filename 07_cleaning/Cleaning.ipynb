{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "***\n",
    "## Learning Objectives\n",
    "* Understand the importance of data cleaning\n",
    "* Learn about the different types of data cleaning\n",
    "\n",
    "## Introduction\n",
    "In this lesson, we'll learn about the importance of data cleaning and the different types of data cleaning. We will be using the Netflix dataset for this lesson.\n",
    "[Netflix](https://www.kaggle.com/datasets/ariyoomotade/netflix-data-cleaning-analysis-and-visualization).\n",
    "\n",
    "Cleaning up data involves:\n",
    "* Removing data that is incorrect, irrelevant, duplicated, or incomplete\n",
    "* Fixing data that is improperly formatted, inaccurate, or missing\n",
    "* Removing outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('netflix1.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the column types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What is an object data type in a Pandas Dataframe?](https://g.co/bard/share/e1f01baab64e) \n",
    "\n",
    "In Pandas, an object data type is used to store data that is not of a specific type, such as strings, numbers, or dates. This can be useful for storing data that may be of different types, such as a column that contains both names and ages.\n",
    "\n",
    "In the code you provided, the `Name` column has an object data type because it contains strings. The `Age` column has an int64 data type because it contains integers. The `Occupation` column also has an object data type because it contains strings.\n",
    "\n",
    "Object data types are less efficient than other data types, such as int64 and float64, because they require more memory to store. However, they are more flexible and can be used to store a wider variety of data.\n",
    "\n",
    "If you are working with a Pandas DataFrame that has a lot of object data types, you may want to consider converting some of the columns to other data types, such as int64 or float64. This can improve the performance of your code.\n",
    "\n",
    "Here are some additional things to know about object data types in Pandas:\n",
    "\n",
    "* Object data types are stored as Python objects.\n",
    "* Object data types are not ordered, meaning that the values in the column are not sorted in any particular order.\n",
    "* Object data types can contain mixed types, meaning that the column can contain strings, numbers, and other objects.\n",
    "* Object data types are less efficient than other data types, such as int64 and float64.\n",
    "\n",
    "I hope this helps! Let me know if you have any other questions about object data types in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we need to convert the objects to strings in the `df`. We also need to convert `date_added` to a datetime object.\n",
    "\n",
    "```python\n",
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "df['release_year'] = df['release_year'].astype(str)\n",
    "df['rating'] = df['rating'].astype(str)\n",
    "df['duration'] = df['duration'].astype(str)\n",
    "df['listed_in'] = df['listed_in'].astype(str)\n",
    "df['description'] = df['description'].astype(str)\n",
    "\n",
    "```\n",
    "\n",
    "The code above was auto-generated. It's not perfect but it gives us a good starting point: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_id         object\n",
    "# type            object\n",
    "# title           object\n",
    "# director        object\n",
    "# country         object\n",
    "# date_added      object\n",
    "# release_year     int64\n",
    "# rating          object\n",
    "# duration        object\n",
    "# listed_in       object\n",
    "\n",
    "# Convert date_added to datetime\n",
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "df.dtypes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get all the rows in duration that end in 'min'\n",
    "mins = df['duration'].str.endswith('min')\n",
    "\n",
    "mins.head()\n",
    "\n",
    "# Add a new column duration_min that contains the duration in minutes\n",
    "df['duration_min'] = df.loc[mins, 'duration'].str.extract('(\\d+)').astype(int)\n",
    "df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for NA values\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're in luck. It seems that there are no missing values in the dataset. For completeness, Let's look at examples of missing data\n",
    "[Here](https://g.co/bard/share/3722d7573f0f) is a string example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", None, \"Peter Smith\"], \"Age\": [30, 25, 40, 20]})\n",
    "df_missing_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the missing name - `None`.  To identify all the missing values in a dataframe, we can run the code above, again: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all the rows with missing values in the Name column\n",
    "df_missing_string[df_missing_string['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string['Name'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sum()` method returns the total missing values. We might be interested in getting a dataframe of values instead: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this to replace, or manipulate the missing values in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"NOT_SPECIFIED\"\n",
    "df_missing_string['Name'] = df_missing_string['Name'].fillna(\"NOT_SPECIFIED\")\n",
    "df_missing_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_string['Name'].fillna(\"NOT_SPECIFIED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers\n",
    "Let's look at numbers. [Here](https://g.co/bard/share/580c6f647392) is a df that has some missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options for filling in missing numbers in a dataframe in pandas. Some of the most common methods include:\n",
    "- Forward fill (ffill): propagates the last valid observation forward to fill the missing values\n",
    "- Backward fill (bfill): propagates the next valid observation backward to fill the missing values\n",
    "- Mean: fills the missing values with the mean of the non-missing values in the column\n",
    "- Median: fills the missing values with the median of the non-missing values in the column\n",
    "- Mode: fills the missing values with the mode of the non-missing values in the column\n",
    "\n",
    "To fill missing values in a pandas dataframe, you can use the `fillna()` method. Here is an example of how to fill missing values with the mean:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_numbers = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", \"Joe Park\", \"Peter Smith\"], \"Age\": [30,None, 40, 20]})\n",
    "df_missing_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same methods are used for identifying the missing values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_numbers.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to assign a specific value the missing value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_numbers['Age'] = df_missing_numbers['Age'].fillna(0) \n",
    "df_missing_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can perform a more complicated operation, like finding the average of the values in a column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the dataframe\n",
    "df_missing_numbers = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", \"Joe Park\", \"Peter Smith\"], \"Age\": [30,None, 40, 20]})\n",
    "df_missing_numbers['Age'] = df_missing_numbers['Age'].fillna(df_missing_numbers['Age'].mean()) # Mean, means average\n",
    "df_missing_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Rows with Missing Values\n",
    "Say we have a DataFrame and we want to remove rows that contain missing values. Pandas provides the dropna() function that can be used to drop either columns or rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_rows = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", None, \"Peter Smith\"], \"Age\": [30, 25, 40, 20], \"Height\": [170, 180, None, 160]})\n",
    "print(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to remove all the rows that do not have a height value, you can use the dropna() method.\n",
    "\n",
    "df_rows.dropna(subset=['Height'], inplace=True)\n",
    "df_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying no subset will check if all the columns are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", None, \"Peter Smith\"], \"Age\": [30, 25, None, 20], \"Height\": [170, 180, None, 160]})\n",
    "df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows.dropna( inplace=True)\n",
    "df_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate rows\n",
    "\n",
    "Here is an example of a dataset that contain duplicated rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with duplicated rows\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'David', 'Bob'],\n",
    "    'Age': [25, 30, 25, 22, 28, 30],\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Houston', 'Los Angeles']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice  rows 1 and 5 as well as 0 and 2 are duplicated pairs. We can only show them by executing the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated()]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have two options: \n",
    "* Keep the first duplicated row (the default behavior of `drop_duplicates`)\n",
    "* Drop *all* duplicated rows\n",
    "* Keep the last duplicated row\n",
    "\n",
    "Let's look at dropping all duplicated rows first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all duplicates in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_all_duplicates = df.drop_duplicates(keep=False)\n",
    "df_drop_all_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the last duplicate row and drop the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_occurrence = df.drop_duplicates(keep='last')\n",
    "print(df_last_occurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with strings\n",
    "\n",
    "Let's look at the Netflix dataset: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('netflix1.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_id` has an *s* at the start of the name. If we can remove the *s*, we can use the column in a more meaningful way. Python has a replace function that can do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"show_id\"] = df[\"show_id\"].replace(\"s\", \"\", regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Let's convert the values to a numerical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"show_id\"] = df[\"show_id\"].astype(int)\n",
    "df.dtypes[\"show_id\"]\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other ways to clean string data. Another common task is to use a part of the string, commonly referred to as a substring. Say we only want the first 2 letters of a string. Here is an example of how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", \"John Smith\"], \"Age\": [30, 25, 40]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first two letters of each name\n",
    "df[\"First Two Letters\"] = df[\"Name\"].str[:2]\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic happens in the `str.[:2]` method. `[:2]` means ge the first two characters of a string.  You can also get the last two characters, for example, by doing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", \"John Smith\"], \"Age\": [30, 25, 40]})\n",
    "\n",
    "df[\"Last Two Letters\"] = df[\"Name\"].str[-2:]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some links to explain indexing (the [:2] and [-2:] in the code above):\n",
    "* https://g.co/bard/share/a7be9b5da5c4\n",
    "* https://www.datacamp.com/tutorial/python-list-index\n",
    "\n",
    "\n",
    "The indexing method is handy but the length of the values you want to extract might not be consistent. If you want to extract the first names of the directors, you can use the split method. This method splits a string into a list of strings based on a separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('netflix1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first names of the directors\n",
    "df['director_name'] = df['director'].str.split(' ').str[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split(' ')` breaks the string into two, or more pieces. For every space `( )`, a new value will be added to the list. If you have \n",
    "`Kirsten Johnson` for example, `split(' ')` will create a list with two values: `['Kirsten', 'Johnson']`. \n",
    "\n",
    "`str[0]` gets the first value in the list. i.e. `Kirsten`\n",
    "\n",
    "Super handy! 🎉\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Transformations\n",
    "We're not quite done with Strings. Regular Expressions is a special type of language for matching patterns in text. It's a language that is available in almost all programming languages and it's extremely powerful once you master it. We'll cover the basics here, but if you want to learn more, check out the [Python Regular Expressions Documentation](https://docs.python.org/3/library/re.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "Imagine you have a dataframe like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = {'Text': ['Alice has 3 apples.', 'Bob likes cats.', 'Charlie has 15 dogs.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you extract only the numbers in `Text`? Short answer - Regular Expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting numbers using regular expression\n",
    "df['Numbers'] = df['Text'].str.extract(r'(\\d+)')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r'(\\d+)'`  says match one or more digits. The key part is `\\d` which says look for number  0 - 9. The `+` says look for one or more of the previous character. So, `\\d+` says look for one or more digits. The parentheses group the digits together. This way we can extract them all at once as a group.\n",
    "\n",
    "Here's a reference table of some commonly used regular expression (regex) patterns and their explanations:\n",
    "\n",
    "| Pattern                | Explanation                                        |\n",
    "|------------------------|----------------------------------------------------|\n",
    "| `\\d`                   | Matches any digit (0-9).                           |\n",
    "| `\\D`                   | Matches any non-digit character.                   |\n",
    "| `\\w`                   | Matches any word character (alphanumeric + underscore). |\n",
    "| `\\W`                   | Matches any non-word character.                   |\n",
    "| `\\s`                   | Matches any whitespace character (space, tab, newline, etc.). |\n",
    "| `\\S`                   | Matches any non-whitespace character.             |\n",
    "| `.`                    | Matches any character except a newline.            |\n",
    "| `^`                    | Matches the start of a string or line.            |\n",
    "| `$`                    | Matches the end of a string or line.              |\n",
    "| `[abc]`                | Matches any of the characters within the square brackets. |\n",
    "| `[^abc]`               | Matches any character except those within the square brackets. |\n",
    "| `[a-z]`                | Matches a character in the range 'a' to 'z'.     |\n",
    "| `*`                    | Matches zero or more occurrences of the preceding pattern. |\n",
    "| `+`                    | Matches one or more occurrences of the preceding pattern. |\n",
    "| `?`                    | Matches zero or one occurrence of the preceding pattern. |\n",
    "| `{n}`                  | Matches exactly 'n' occurrences of the preceding pattern. |\n",
    "| `{n,}`                 | Matches 'n' or more occurrences of the preceding pattern. |\n",
    "| `{n,m}`                | Matches between 'n' and 'm' occurrences of the preceding pattern. |\n",
    "| `()`                   | Groups patterns together.                        |\n",
    "| `\\`                    | Escapes a special character or indicates a special sequence. |\n",
    "\n",
    "These are just a few of the most commonly used regex patterns. Regular expressions can get quite complex, so this table serves as a starting point. If you want to learn more or explore more advanced patterns, you can refer to online regex documentation and tutorials.\n",
    "\n",
    "Another useful site is [regex101](https://regex101.com/). This site allows you to test your regex patterns against a sample text of your choosing. It also explains each part of the regex pattern and highlights the characters that are matched by each part.\n",
    "\n",
    "Here is another example of using a regex to extract information from a string:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample DataFrame\n",
    "data = {'Description': ['Product Code: ABC123', 'Product Code: DEF456', 'Other text']}\n",
    "df = pd.DataFrame(data)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting product codes using regular expression\n",
    "pattern = r'Product Code: (\\w+)'\n",
    "df['Product Code'] = df['Description'].str.extract(pattern)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex `Product Code: (\\w+)` reads as follows:\n",
    "Use the string `Product Code: ` to find a match.\n",
    "Then, match any word character (letter, number, or underscore) one or more times.\n",
    "The parentheses around `\\w+` indicate that this is a capture group, which signals to Pandas that we want to extract this part of the regex. Put another way, we only want the part of the regex inside the parentheses.\n",
    "\n",
    "Regular Expressions definitely takes a while to get used to, but they can be a powerful tool once you get the hang of them. \n",
    "\n",
    "The good news ,though, is that you can use Bard or Chat GPT to generate them for you. [Here](https://g.co/bard/share/55cbf48ad765) is the Bard version:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map()` is a powerful dataframe method that lets you apply a function to every element in a column. For example, if you wanted to add 1 to every element in a column, you could do:\n",
    "\n",
    "```python\n",
    "df['column1'] = df['column1'].map(lambda x: x + 1)\n",
    "```\n",
    "Let's start with `lambda x: x + 1`. [Lambdas](https://g.co/bard/share/cfbc9c2a2f4a) are just quick functions that you can write in one line. The above lambda is the same as:\n",
    "\n",
    "```python\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "```\n",
    "The `map()` method takes every element in the column it is being applied to and passes it into the lambda function you wrote. The result of the lambda function is then put into the new column. In the above example, we are taking every element in `column1`, adding 1 to it, and then storing the result in `column1`.\n",
    "\n",
    "Here is a more concrete example of using `map()` to change country names:\n",
    "\n",
    "```python\n",
    "df['Country'] = df['Country'].map(lambda x: 'United States' if x == 'US' else x)\n",
    "```\n",
    "\n",
    "Here are few examples Chat-GPT gave me: \n",
    "```python\n",
    "# Example 1: Lambda function with one argument\n",
    "square = lambda x: x ** 2\n",
    "print(square(4))  # Output: 16\n",
    "\n",
    "# Example 2: Lambda function with multiple arguments\n",
    "add = lambda x, y: x + y\n",
    "print(add(5, 3))  # Output: 8\n",
    "\n",
    "# Example 3: Lambda function as an argument to another function\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "squared_numbers = list(map(lambda x: x ** 2, numbers))\n",
    "print(squared_numbers)  # Output: [1, 4, 9, 16, 25]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Age\n",
       "0    John Doe   30\n",
       "1    Jane Doe   25\n",
       "2  John Smith   40"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Name\": [\"John Doe\", \"Jane Doe\", \"John Smith\"], \"Age\": [30, 25, 40]})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Age\n",
      "0    JOHN DOE   30\n",
      "1    JANE DOE   25\n",
      "2  JOHN SMITH   40\n"
     ]
    }
   ],
   "source": [
    "def uppercase(string):\n",
    "    return string.upper()\n",
    "\n",
    "df[\"Name\"] = df[\"Name\"].map(uppercase)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map()` can also take a dictionary as an argument. The dictionary should contain keys that match the values in the Series. The function `map()` will match each value in the Series to a key in the dictionary and replace that value with the associated dictionary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Gender\n",
       "0    Alice      M\n",
       "1      Bob      F\n",
       "2  Charlie      M"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Gender': ['M', 'F', 'M']}\n",
    "df_2 = pd.DataFrame(data)\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Gender\n",
      "0    Alice    Male\n",
      "1      Bob  Female\n",
      "2  Charlie    Male\n"
     ]
    }
   ],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Gender': ['M', 'F', 'M']}\n",
    "df_2 = pd.DataFrame(data)\n",
    "\n",
    "# Mapping dictionary for gender codes to gender names\n",
    "gender_mapping = {'M': 'Male', 'F': 'Female'}\n",
    "\n",
    "# Using map() to replace gender codes with gender names\n",
    "df_2['Gender'] = df_2['Gender'].map(gender_mapping)\n",
    "\n",
    "print(df_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
